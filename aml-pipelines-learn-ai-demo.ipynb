{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning Pipelines: LearnAI Demo\n",
    "\n",
    "This Notebook shows basic construction of a **pipeline** and some of its key features. \n",
    "\n",
    "Do not forget to read [Azure Machine Learning Pipelines](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-ml-pipelines) overview, and try [creating your first pipeline](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-create-your-first-pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 0.0.0+dev\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up AML\n",
    "### Initialize Workspace\n",
    "\n",
    "Initialize a [workspace](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace(class%29) object from persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\repos\\learn-ai\\aml_config\\config.json\n",
      "Workspace sanpilinternal is loaded\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace {} is loaded\".format(ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to the datastore\n",
    "We are uploading a file to the datastore that is attached to the workspace. We will use this file later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./data/traindata.csv\n",
      "Uploaded ./data/traindata.csv, 1 files out of an estimated total of 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_52d68aec046c448c94866cf3b31f333f"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "# Default file storage\n",
    "def_file_store = ws.get_default_datastore() \n",
    "\n",
    "#def_file_store = Datastore(ws, \"workspacefilestore\")\n",
    "#print(\"Blobstore's name: {}\".format(def_blob_store.name))\n",
    "\n",
    "#def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "#print(\"Blobstore's name: {}\".format(def_blob_store.name))\n",
    "\n",
    "# target_path is the directory at the destination\n",
    "def_file_store.upload_files(['./data/traindata.csv'], \n",
    "                                  target_path = 'data', \n",
    "                                  overwrite = True, \n",
    "                                  show_progress = True)\n",
    "\n",
    "# Here we are reusing the def_blob_store we created earlier\n",
    "# def_blob_store.upload_files([\"./data/traindata.csv\"], \n",
    "#                             target_path=\"data\", \n",
    "#                             overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See your files using Azure Portal\n",
    "Once you successfully uploaded the files, you can browse to them (or upload more files) using [Azure Portal](https://portal.azure.com). At the portal, make sure you have selected your subscription (click *Resource Groups* and then select the subscription). Then look for your **Machine Learning Workspace**. It has a link to your storage. Click on the storage link. It will take you to a page where you can see [Blobs](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction), [Files](https://docs.microsoft.com/en-us/azure/storage/files/storage-files-introduction), [Tables](https://docs.microsoft.com/en-us/azure/storage/tables/table-storage-overview), and [Queues](https://docs.microsoft.com/en-us/azure/storage/queues/storage-queues-introduction). We have just uploaded a file to the Blob storage and another one to the File storage. You should be able to see both of these files in their respective locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve or create an Azure Machine Learning compute\n",
    "Azure Machine Learning Compute is a service for provisioning and managing clusters of Azure virtual machines for running machine learning workloads. Let's create a new Azure Machine Learning Compute in the current workspace, if it doesn't already exist. We will then run the training script on this compute target.\n",
    "\n",
    "If we could not find the compute with the given name in the previous cell, then we will create a new compute here. We will create an Azure Machine Learning Compute containing **STANDARD_D2_V2 CPU VMs**. This process is broken down into the following steps:\n",
    "\n",
    "1. Create the configuration\n",
    "2. Create the Azure Machine Learning compute\n",
    "\n",
    "**This process will take about 3 minutes and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target: gpucluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "\n",
    "aml_compute_target = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"Found existing compute target: {}\".format(aml_compute.name))\n",
    "except:\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 1, \n",
    "                                                                max_nodes = 4)    \n",
    "    aml_compute = AmlCompute.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    print(\"Created new compute target: {}\".format(aml_compute.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait for this call to finish before proceeding (you will see the asterisk turning to a number).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Pipeline\n",
    "A Step is a unit of execution. Step typically needs a target of execution (compute target), a script to execute, and may require script arguments and inputs, and can produce outputs. The step also could take a number of other parameters. Azure Machine Learning Pipelines currently has these built-in Steps: [PythonScriptStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.python_script_step.pythonscriptstep?view=azure-ml-py), [EstimatorStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.estimator_step.estimatorstep?view=azure-ml-py), [MpiStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.mpi_step.mpistep?view=azure-ml-py), [AdlaStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.adla_step.adlastep?view=azure-ml-py), [DataTransferStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.data_transfer_step.datatransferstep?view=azure-ml-py), [DatabricksStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.databricks_step.databricksstep?view=azure-ml-py), and [HyperDriveStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.hyper_drive_step.hyperdrivestep?view=azure-ml-py).\n",
    "\n",
    "### Define a Pipeline Step with inputs and outputs \n",
    "#### Modeling input data\n",
    "A step in the pipeline can take data as input. This data can be a data source that lives in one of the accessible data locations, or intermediate data produced by a previous step in the pipeline. An already existing data is typically called a Datasource and is represented by [DataReference](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.data_reference.datareference?view=azure-ml-py) object. A DataReference could be a pointer to a file or a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataReference object created\n"
     ]
    }
   ],
   "source": [
    "from azureml.data.data_reference import DataReference\n",
    "file_input_data = DataReference(\n",
    "    datastore=def_file_store,\n",
    "    data_reference_name=\"raw_train_data\",\n",
    "    path_on_datastore=\"data/traindata.csv\")\n",
    "print(\"DataReference object created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling output or intermediate data\n",
    "Intermediate data (or output of a Step) is represented by [PipelineData](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipelinedata?view=azure-ml-py) object. PipelineData can be produced by one step and consumed in another step by providing the PipelineData object as an output of one step and the input of one or more steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineData object created\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "processed_train_data = PipelineData(\"processed_train_data\",datastore=def_file_store)\n",
    "print(\"PipelineData object created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Dataprep Step that consumes train data (datasource) and produces an intermediate data.\n",
    "Here we are using a **PythonScriptStep**, a basic built-in step to run a Python Script on the compute target. The following code will create a PythonScriptStep to be executed in the Azure Machine Learning Compute we created above using dataprep.py, a file available in the project folder.\n",
    "\n",
    "If you open `dataprep.py` in the local machine and examine the arguments, inputs, and outputs for the script, you will get a good sense of why the script argument names used below are important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataprepStep step created\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "project_folder = \"scripts/dataprep\"\n",
    "dataprepStep = PythonScriptStep(name=\"dataprep_step\",\n",
    "                         script_name=\"dataprep.py\", \n",
    "                         arguments=[\"--input_data\", file_input_data, \"--processed_data\", processed_train_data],\n",
    "                         inputs=[file_input_data],\n",
    "                         outputs=[processed_train_data],\n",
    "                         compute_target=aml_compute, \n",
    "                         source_directory=project_folder,\n",
    "                         allow_reuse=True)\n",
    "print(\"dataprepStep step created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the above call to PythonScriptStep(), the flag *allow_reuse* determines whether the step should reuse previous results when run with the same settings/inputs. This flag's default value is *True*; the default is set to *True* because, when inputs and parameters have not changed, we typically do not want to re-run a given pipeline step. \n",
    "\n",
    "If *allow_reuse* is set to *False*, a new run will always be generated for this step during pipeline execution. The *allow_reuse* flag can come in handy in situations where you do *not* want to re-run a pipeline step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Train Step that consumes intermediate data produced Data Prep step and produces an intermediate data.\n",
    "In this step, we define a step that consumes an intermediate data and produces intermediate data.\n",
    "\n",
    "Make sure you open `train.py` in your local machine and examine the arguments, inputs, and outputs for the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainStep step created\n"
     ]
    }
   ],
   "source": [
    "project_folder = \"scripts/train\"\n",
    "\n",
    "output_model_location = PipelineData(\"output_model_location\",datastore=def_file_store)\n",
    "\n",
    "trainStep = PythonScriptStep(name=\"train_step\",\n",
    "                         script_name=\"train.py\", \n",
    "                         arguments=[\"--input_data\", processed_train_data, \"--output_train\", output_model_location],\n",
    "                         inputs=[processed_train_data],\n",
    "                         outputs=[output_model_location],\n",
    "                         compute_target=aml_compute, \n",
    "                         source_directory=project_folder,\n",
    "                         allow_reuse=True)\n",
    "\n",
    "print(\"trainStep step created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Compare Step that consumes a datasource and an intermediate data and produces an intermediate data.\n",
    "In this step, we define a step that consumes a datasource and an intermediate data and produces an intermediate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataReference object created\n"
     ]
    }
   ],
   "source": [
    "# Location of the model to be compared\n",
    "prod_model_location = DataReference(\n",
    "    datastore=def_file_store,\n",
    "    data_reference_name=\"prod_model_location\",\n",
    "    path_on_datastore=\"models\")\n",
    "print(\"DataReference object created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pass in the version of the existing model to compare as a [PipelineParameter](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.graph.pipelineparameter?view=azure-ml-py). This will help with calling the REST endpoint of the published pipeline later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline parameter created\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "model_version_number = PipelineParameter(name=\"model_version\", default_value=1.2)\n",
    "print(\"Pipeline parameter created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you open `compare.py` in your local machine and examine the arguments, inputs, and outputs for the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compareStep step created\n"
     ]
    }
   ],
   "source": [
    "project_folder = \"scripts/compare\"\n",
    "\n",
    "compare_result = PipelineData(\"compare_result\",datastore=def_file_store)\n",
    "\n",
    "compareStep = PythonScriptStep(name=\"compare_step\",\n",
    "                         script_name=\"comparemodels.py\", \n",
    "                         arguments=[\"--new_model_location\", output_model_location,\n",
    "                                    \"--prod_model_location\", prod_model_location,\n",
    "                                    \"--model_version\", model_version_number,\n",
    "                                    \"--compare_result\", compare_result],\n",
    "                         inputs=[output_model_location, prod_model_location],\n",
    "                         outputs=[compare_result],\n",
    "                         compute_target=aml_compute, \n",
    "                         source_directory=project_folder,\n",
    "                         allow_reuse=True)\n",
    "\n",
    "print(\"compareStep step created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the pipeline\n",
    "Once we have the steps (or steps collection), we can build the [pipeline](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py). By deafult, all these steps will start as soon as all dependencies are fulfilled. \n",
    "\n",
    "Submit a pipeline using [submit](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment%28class%29?view=azure-ml-py#submit). When submit is called, a [PipelineRun](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipelinerun?view=azure-ml-py) is created which in turn creates [StepRun](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.steprun?view=azure-ml-py) objects for each step in the workflow.\n",
    "\n",
    "You have the option to [validate](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py#validate) the pipeline prior to submitting for run. The platform runs validation steps such as checking for circular dependencies and parameter checks etc. even if you do not explicitly call validate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built\n",
      "Pipeline validation complete\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "steps = [dataprepStep, trainStep, compareStep]\n",
    "\n",
    "training_pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "print (\"Pipeline is built\")\n",
    "\n",
    "training_pipeline.validate()\n",
    "print(\"Pipeline validation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the pipeline\n",
    "[Submitting](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py#submit) the pipeline involves creating an [Experiment](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment?view=azure-ml-py) object and providing the built pipeline for submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step dataprep_step [6ac7aebb][91bd7677-ace8-4b40-9bf6-d0675d02dba2], (This step is eligible to reuse a previous run's output)\n",
      "Created step train_step [a5f036cf][4740fe4c-eb1c-4196-bd4a-a8e8236ac522], (This step is eligible to reuse a previous run's output)\n",
      "Created step compare_step [d951aeb1][70507a57-70e9-4e29-b44f-78d5e9411fc1], (This step is eligible to reuse a previous run's output)\n",
      "Using data reference raw_train_data for StepId [b953a2be][46eadc67-772e-4db5-b628-f54d35638cb4], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference prod_model_location for StepId [12a75824][fca81c16-d6fb-4f97-8cc2-6f3a5e60cbda], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted pipeline run: 3a36ea90-91aa-4028-94e8-4e302a280dd4\n",
      "Pipeline is submitted for execution\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "training_pipeline_run = Experiment(ws, 'Compare_Models_Experiment').submit(training_pipeline, regenerate_outputs=False)\n",
    "print(\"Pipeline is submitted for execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If regenerate_outputs is set to True, a new submit will always force generation of all step outputs, and disallow data reuse for any step of this run. Once this run is complete, however, subsequent runs may reuse the results of this run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the pipeline run\n",
    "We are going to use the RunDetails widget to examine the run of the pipeline. You can click each row below to get more details on the step runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961dda7743204b64ac1d0dc364f98f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(training_pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the pipeline\n",
    "Once you are satisfied with the results of your experiment, you may want to publish the pipeline to get a REST endpoint so the pipeline can be invoked later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The published pipeline ID is f48cba85-6b1a-47e8-80c3-05bdb4aec250\n"
     ]
    }
   ],
   "source": [
    "published_training_pipeline = training_pipeline.publish(name=\"Compare_Models_Pipeline\", \n",
    "                                                     description=\"This pipeline compares models\")\n",
    "print(\"The published pipeline ID is {}\".format(published_train_pipeline.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run published pipeline using its REST endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The published pipeline REST endpoint is https://eastus2euap.aether.ms/api/v1.0/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/PipelinesUsabilityStudy/providers/Microsoft.MachineLearningServices/workspaces/sanpilinternal/PipelineRuns/PipelineSubmit/878b4cc2-9366-4610-af06-c13f06cf1f99\n",
      "The run ID is 157f2dfe-9adf-44b6-8131-60f8ee961c58\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.authentication import AzureCliAuthentication\n",
    "import requests\n",
    "\n",
    "cli_auth = AzureCliAuthentication()\n",
    "aad_token = cli_auth.get_authentication_header()\n",
    "\n",
    "training_pipeline_rest_ep = published_training_pipeline.endpoint\n",
    "\n",
    "print(\"The published pipeline REST endpoint is {}\".format(training_pipeline_rest_ep))\n",
    "\n",
    "# specify the param when running the pipeline\n",
    "response = requests.post(training_pipeline_rest_ep, \n",
    "                         headers=aad_token, \n",
    "                         json={\"ExperimentName\": \"Compare_v2_Models_Experiment\",\n",
    "                               \"RunSource\": \"SDK\",\n",
    "                               \"ParameterAssignments\": {\"model_version\": 2.0}})\n",
    "run_id = response.json()[\"Id\"]\n",
    "\n",
    "print(\"The run ID is {}\".format(run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "diray"
   }
  ],
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
