{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning Pipelines: LearnAI Demo\n",
    "\n",
    "This Notebook shows basic construction of a **pipeline** and some of its key features. \n",
    "\n",
    "Do not forget to read [Azure Machine Learning Pipelines](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-ml-pipelines) overview, and try following along the article [creating your first pipeline](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-create-your-first-pipeline).\n",
    "\n",
    "In this demo we are creating an AML Pipeline that has three steps. A data preparation step, a training step, and a compare step that compares the newly built model with the model currently in production. **All scripts are for demonstration purpose only, you may replace the scripts with actual code when you want to reuse this sample.**\n",
    "\n",
    "For a more real-life sample using AML Pipelines, please refer to the official git repo at https://aka.ms/aml-pipeline-notebooks, especially https://aka.ms/pl-batch-score and https://aka.ms/pl-style-trans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up AML\n",
    "### Initialize Workspace\n",
    "\n",
    "Initialize a [workspace](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace(class%29) object from persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace {} is loaded\".format(ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to the datastore\n",
    "We are uploading the training data and current production model to the datastore that is attached to the workspace. We will use these files later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "# Get the default blob storage\n",
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "print(\"Blobstore's name: {}\".format(def_blob_store.name))\n",
    "\n",
    "# target_path is the directory at the destination\n",
    "# Uploading training file\n",
    "def_blob_store.upload_files(['./data/traindata.csv'],\n",
    "                            target_path = 'data',\n",
    "                            overwrite = True, \n",
    "                            show_progress = True)\n",
    "\n",
    "# Uploading model in production\n",
    "def_blob_store.upload_files(['./model/model.pkl'],\n",
    "                            target_path = 'model',\n",
    "                            overwrite = True, \n",
    "                            show_progress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See your files using Azure Portal\n",
    "Once you successfully uploaded the files, you can browse to them (or upload more files) using [Azure Portal](https://portal.azure.com). At the portal, make sure you have selected your subscription (click *Resource Groups* and then select the subscription). Then look for your **Machine Learning Workspace**. It has a link to your storage. Click on the storage link. It will take you to a page where you can see [Blobs](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction), [Files](https://docs.microsoft.com/en-us/azure/storage/files/storage-files-introduction), [Tables](https://docs.microsoft.com/en-us/azure/storage/tables/table-storage-overview), and [Queues](https://docs.microsoft.com/en-us/azure/storage/queues/storage-queues-introduction). We have just uploaded a file to the Blob storage. You should be able to see the file in the blob storage location. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve or create an Azure Machine Learning compute\n",
    "Azure Machine Learning Compute is a service for provisioning and managing clusters of Azure virtual machines for running machine learning workloads. Let's create a new Azure Machine Learning Compute in the current workspace, if it doesn't already exist. We will then run the training script on this compute target.\n",
    "\n",
    "If we could not find the compute with the given name in the previous cell, then we will create a new compute here. We will create an Azure Machine Learning Compute containing **STANDARD_D2_V2 CPU VMs and STANDARD_NC6 GPU VMs**. This process is broken down into the following steps:\n",
    "\n",
    "1. Create the configuration\n",
    "2. Create the Azure Machine Learning compute\n",
    "\n",
    "**This process will take about 3 minutes and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "\n",
    "# CPU Cluster\n",
    "cpu_compute_target = \"cpucluster\"\n",
    "\n",
    "try:\n",
    "    cpu_compute = AmlCompute(ws, cpu_compute_target)\n",
    "    print(\"Found existing compute target: {}\".format(cpu_compute.name))\n",
    "except:\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 1,\n",
    "                                                                max_nodes = 4)\n",
    "    cpu_compute = AmlCompute.create(ws, cpu_compute_target, provisioning_config)\n",
    "    cpu_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    print(\"Created new compute target: {}\".format(cpu_compute.name))\n",
    "\n",
    "# GPU Cluster\n",
    "gpu_compute_target = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    gpu_compute = AmlCompute(ws, gpu_compute_target)\n",
    "    print(\"Found existing compute target: {}\".format(gpu_compute.name))\n",
    "except:\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\",\n",
    "                                                                min_nodes = 1,\n",
    "                                                                max_nodes = 4)\n",
    "    gpu_compute = AmlCompute.create(ws, gpu_compute_target, provisioning_config)\n",
    "    gpu_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    print(\"Created new compute target: {}\".format(gpu_compute.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Pipeline\n",
    "A Step is a unit of execution. Step typically needs a target of execution (compute target), a script to execute, and may require script arguments and inputs, and can produce outputs. The step also could take a number of other parameters. Azure Machine Learning Pipelines currently has these built-in Steps: [PythonScriptStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.python_script_step.pythonscriptstep?view=azure-ml-py), [EstimatorStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.estimator_step.estimatorstep?view=azure-ml-py), [MpiStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.mpi_step.mpistep?view=azure-ml-py), [AdlaStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.adla_step.adlastep?view=azure-ml-py), [DataTransferStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.data_transfer_step.datatransferstep?view=azure-ml-py), [DatabricksStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.databricks_step.databricksstep?view=azure-ml-py), and [HyperDriveStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.hyper_drive_step.hyperdrivestep?view=azure-ml-py).\n",
    "\n",
    "### Define a Pipeline Step with inputs and outputs \n",
    "#### Modeling input data\n",
    "A step in the pipeline can take data as input. This data can be a data source that lives in one of the accessible data locations, or intermediate data produced by a previous step in the pipeline. An already existing data is typically called a Datasource and is represented by [DataReference](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.data_reference.datareference?view=azure-ml-py) object. A DataReference could be a pointer to a file or a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "file_input_data = DataReference(\n",
    "    datastore=def_blob_store,\n",
    "    data_reference_name=\"raw_train_data\",\n",
    "    path_on_datastore=\"data/traindata.csv\")\n",
    "print(\"DataReference object created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling output or intermediate data\n",
    "Intermediate data (or output of a Step) is represented by [PipelineData](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipelinedata?view=azure-ml-py) object. PipelineData can be produced by one step and consumed in another step by providing the PipelineData object as an output of one step and the input of one or more steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "processed_train_data = PipelineData(\"processed_train_data\", datastore=def_blob_store)\n",
    "print(\"PipelineData object created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Dataprep Step that consumes train data (datasource) and produces an intermediate data.\n",
    "Here we are using a **PythonScriptStep**, a basic built-in step to run a Python Script on the compute target. The following code will create a PythonScriptStep to be executed in the Azure Machine Learning Compute we created above using dataprep.py, a file available in the project folder.\n",
    "\n",
    "If you open `dataprep.py` in the local machine and examine the arguments, inputs, and outputs for the script, you will get a good sense of why the script argument names used below are important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "project_folder = \"scripts/dataprep\"\n",
    "\n",
    "dataprepStep = PythonScriptStep(name=\"dataprep_step\",\n",
    "                         script_name=\"dataprep.py\",\n",
    "                         arguments=[\"--input_data\", file_input_data, \"--processed_data\", processed_train_data],\n",
    "                         inputs=[file_input_data],\n",
    "                         outputs=[processed_train_data],\n",
    "                         compute_target=cpu_compute,\n",
    "                         source_directory=project_folder,\n",
    "                         allow_reuse=False)\n",
    "\n",
    "print(\"dataprepStep step created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the above call to PythonScriptStep(), the flag *allow_reuse* determines whether the step should reuse previous results when run with the same settings/inputs. This flag's default value is *True*; the default is set to *True* because, when inputs and parameters have not changed, we typically do not want to re-run a given pipeline step. \n",
    "\n",
    "If *allow_reuse* is set to *False*, a new run will always be generated for this step during pipeline execution. The *allow_reuse* flag can come in handy in situations where you do *not* want to re-run a pipeline step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Train Step that consumes intermediate data produced Data Prep step and produces an intermediate data.\n",
    "In this step, we define a step that consumes an intermediate data and produces intermediate data.\n",
    "\n",
    "Make sure you open `train.py` in your local machine and examine the arguments, inputs, and outputs for the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = \"scripts/train\"\n",
    "\n",
    "output_model_location = PipelineData(\"output_model_location\", datastore=def_blob_store)\n",
    "\n",
    "trainStep = PythonScriptStep(name=\"train_step\",\n",
    "                         script_name=\"train.py\",\n",
    "                         arguments=[\"--input_data\", processed_train_data, \"--output_train\", output_model_location],\n",
    "                         inputs=[processed_train_data],\n",
    "                         outputs=[output_model_location],\n",
    "                         compute_target=gpu_compute,\n",
    "                         source_directory=project_folder,\n",
    "                         allow_reuse=False)\n",
    "\n",
    "print(\"trainStep step created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Compare Step that consumes a datasource and an intermediate data and produces an intermediate data.\n",
    "In this step, we define a step that consumes a datasource and an intermediate data and produces an intermediate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the model to be compared\n",
    "prod_model_location = DataReference(\n",
    "    datastore=def_blob_store,\n",
    "    data_reference_name=\"prod_model_location\",\n",
    "    path_on_datastore=\"models\")\n",
    "print(\"DataReference object created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pass in the version of the existing model to compare as a [PipelineParameter](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.graph.pipelineparameter?view=azure-ml-py). This will help with calling the REST endpoint of the published pipeline later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "model_version_number = PipelineParameter(name=\"model_version\", default_value=1.0)\n",
    "print(\"Pipeline parameter created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you open `compare.py` in your local machine and examine the arguments, inputs, and outputs for the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = \"scripts/compare\"\n",
    "\n",
    "compare_result = PipelineData(\"compare_result\", datastore=def_blob_store)\n",
    "\n",
    "compareStep = PythonScriptStep(name=\"compare_step\",\n",
    "                         script_name=\"comparemodels.py\",\n",
    "                         arguments=[\"--new_model_location\", output_model_location,\n",
    "                                    \"--prod_model_location\", prod_model_location,\n",
    "                                    \"--model_version\", model_version_number,\n",
    "                                    \"--compare_result\", compare_result],\n",
    "                         inputs=[output_model_location, prod_model_location],\n",
    "                         outputs=[compare_result],\n",
    "                         compute_target=cpu_compute,\n",
    "                         source_directory=project_folder,\n",
    "                         allow_reuse=False)\n",
    "\n",
    "print(\"compareStep step created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the pipeline\n",
    "Once we have the steps (or steps collection), we can build the [pipeline](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py). By deafult, all these steps will start as soon as all dependencies are fulfilled. \n",
    "\n",
    "Submit a pipeline using [submit](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment%28class%29?view=azure-ml-py#submit). When submit is called, a [PipelineRun](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipelinerun?view=azure-ml-py) is created which in turn creates [StepRun](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.steprun?view=azure-ml-py) objects for each step in the workflow.\n",
    "\n",
    "You have the option to [validate](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py#validate) the pipeline prior to submitting for run. The platform runs validation steps such as checking for circular dependencies and parameter checks etc. even if you do not explicitly call validate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "steps = [dataprepStep, trainStep, compareStep]\n",
    "\n",
    "training_pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "print(\"Pipeline is built\")\n",
    "\n",
    "training_pipeline.validate()\n",
    "print(\"Pipeline validation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the pipeline\n",
    "[Submitting](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py#submit) the pipeline involves creating an [Experiment](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment?view=azure-ml-py) object and providing the built pipeline for submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "training_pipeline_run = Experiment(ws, 'Compare_Models_Experiment').submit(training_pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline is submitted for execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If regenerate_outputs is set to True, a new submit will always force generation of all step outputs, and disallow data reuse for any step of this run. Once this run is complete, however, subsequent runs may reuse the results of this run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the pipeline run\n",
    "We are going to use the RunDetails widget to examine the run of the pipeline. You can click each row below to get more details on the step runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(training_pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the pipeline\n",
    "Once you are satisfied with the results of your experiment, you may want to publish the pipeline to get a REST endpoint so the pipeline can be invoked later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_training_pipeline = training_pipeline.publish(name=\"Compare_Models_Pipeline\",\n",
    "                                                        description=\"This pipeline compares models\")\n",
    "print(\"The published pipeline ID is {}\".format(published_training_pipeline.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run published pipeline using its REST endpoint\n",
    "To invoke the run of the preceding pipeline, you need an Azure Active Directory authentication header token, as described in [AzureCliAuthentication](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.authentication.azurecliauthentication?view=azure-ml-py) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import AzureCliAuthentication\n",
    "import requests\n",
    "\n",
    "cli_auth = AzureCliAuthentication()\n",
    "aad_token = cli_auth.get_authentication_header()\n",
    "\n",
    "training_pipeline_rest_ep = published_training_pipeline.endpoint\n",
    "\n",
    "print(\"The published pipeline REST endpoint is {}\".format(training_pipeline_rest_ep))\n",
    "\n",
    "# specify the param when running the pipeline\n",
    "response = requests.post(training_pipeline_rest_ep,\n",
    "                         headers=aad_token,\n",
    "                         json={\"ExperimentName\": \"Compare_v2_Models_Experiment\",\n",
    "                               \"RunSource\": \"SDK\",\n",
    "                               \"ParameterAssignments\": {\"model_version\": 2.0}})\n",
    "pipeline_run_id = response.json()[\"Id\"]\n",
    "\n",
    "print(\"The run ID is {}\".format(pipeline_run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the run\n",
    "We can examine the run of the pipeline that we just invoked via the REST endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineRun\n",
    "pub_pipeline_run = PipelineRun(Experiment(ws, \"Compare_v2_Models_Experiment\"), pipeline_run_id)\n",
    "RunDetails(pub_pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Than you!\n",
    "That's it. Thank you for watching! "
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "diray"
   }
  ],
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
